[default]
max_new_tokens = 500
stop_sequences = ["###STOP###", "\n\n\n", "<|endoftext|>"]

[default.tool_example_generation]
max_new_tokens = 1000
stop_sequences = ["\n\n\n"]

[ibm-granite-3-2-8b-instruct]
max_new_tokens = 500
stop_sequences = ["###STOP###", "\n\n\n", "<|endoftext|>"]

[ibm-granite-3-2-8b-instruct.tool_example_generation]
max_new_tokens = 1000
stop_sequences = ["\n\n\n"]

[meta-llama-llama-3-405b-instruct]
max_new_tokens = 500
stop_sequences = ["\n\n\n", "\n\n"]

[meta-llama-llama-3-405b-instruct.tool_example_generation]
max_new_tokens = 1000
stop_sequences = ["\n\n\n"]

[mistralai-mistral-large]
max_new_tokens = 500
stop_sequences = ["\n\n\n", "\n\n"]

[mistralai-mistral-large.tool_example_generation]
max_new_tokens = 1000
stop_sequences = ["\n\n\n"]

[mistralai-mistral-medium-2505]
max_new_tokens = 500
stop_sequences = ["\n\n\n", "\n\n"]

[mistralai-mistral-medium-2505.tool_example_generation]
max_new_tokens = 1000
stop_sequences = ["\n\n\n"]

[ibm-granite-4-h-small]
max_new_tokens = 500
stop_sequences = ["\n\n\n", "\n\n"]

[ibm-granite-4-h-small.tool_example_generation]
max_new_tokens = 1000
stop_sequences = ["\n\n\n"]
